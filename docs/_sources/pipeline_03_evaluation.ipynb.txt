{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "In this notebook, different measures are investigated to quantify the effect of correcting SpaceM ion intensity data for partial pixel-cell overlap.\n",
    "Moreover, The effects of the correction on different metabolites is visualized.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "import outer_spacem as osm\n",
    "import sys\n",
    "sys.path.append('/home/mklein/spacem')\n",
    "sys.path.append('/Volumes/mklein/spacem')\n",
    "sys.path.append('/home/mklein/FDA_project')\n",
    "from src.correction import *\n",
    "from src.evaluation import intermixing, MetaboliteAnalysis\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['retina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "if platform.system() == \"Darwin\":\n",
    "    target_path = '/Volumes/mklein/FDA_project/data/Lx_Glioblastoma'\n",
    "    if True:\n",
    "        target_path = '/Users/mariusklein/Local_Project_Files/FDA_project/data/Lx_Glioblastoma'\n",
    "\n",
    "else:\n",
    "    target_path = '/home/mklein/FDA_project/data/Lx_Glioblastoma'\n",
    "\n",
    "condition_name = 'condition'\n",
    "well_name = 'rowcol'\n",
    "project = 'Lx_Glioblastoma'\n",
    "analysis_path = target_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the uncorrected and ISM-corrected dataset from file. Additionally, loading the metadata CSV file to filter out excluded wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = ad.read(os.path.join(target_path, \"gen_batch_sm_matrix.h5ad\"))\n",
    "adata_cor = ad.read(os.path.join(target_path, \"corrected_batch_sm_matrix.h5ad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(target_path, 'metadata.csv')\n",
    "samples = list(set(adata.obs['well']))\n",
    "\n",
    "if os.path.exists(metadata_path):\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    if well_name not in metadata.columns:\n",
    "        if \"row\" in metadata.columns and \"col\" in metadata.columns:\n",
    "            metadata[well_name] = metadata['row'].astype(str) + metadata['col'].astype(str)\n",
    "        elif \"slide\" in metadata.columns and \"well\" in metadata.columns:\n",
    "            metadata[well_name] = \"S\" + metadata['slide'].astype(str) + \"_W\" + metadata['well'].astype(str)\n",
    "        else:\n",
    "            raise Exception(\"Could not find condition column in metadata file and no default composition worked.\")\n",
    "    samples = list(metadata[well_name])\n",
    "\n",
    "def assign_conditions(adata):\n",
    "    index = adata.obs.index.name\n",
    "    new_obs = adata.obs.reset_index()\n",
    "    \n",
    "    new_obs = pd.merge(new_obs, metadata[[well_name, condition_name]], \n",
    "                       how='inner', left_on='well', right_on=well_name).set_index(index)\n",
    "    \n",
    "    adata = adata[new_obs.index, :].copy()\n",
    "    adata.obs = new_obs\n",
    "    if 'keep_conditions' in globals():\n",
    "        adata = adata[adata.obs[condition_name].isin(keep_conditions), :].copy()\n",
    "    return adata\n",
    "\n",
    "adata = assign_conditions(adata)\n",
    "adata_cor = assign_conditions(adata_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.crosstab(adata.obs['well'], adata.obs[condition_name], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_molecules = adata.var_names.intersection(adata_cor.var_names)\n",
    "included_cells = adata.obs_names.intersection(adata_cor.obs_names)\n",
    "\n",
    "def subset_molecules(adata):\n",
    "    \n",
    "    return adata[included_cells, included_molecules].copy()\n",
    "\n",
    "adata = subset_molecules(adata)\n",
    "adata_cor = subset_molecules(adata_cor)\n",
    "\n",
    "print(adata.shape)\n",
    "print(adata_cor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the loaded datasets are filtered:\n",
    "\n",
    "- cells need non-zero intensities for at least 10 ions.\n",
    "- ions need non-zero intensities for at least 200 cells.\n",
    "\n",
    "After that, the sets are preprocessed in different ways:\n",
    "\n",
    "- intensties are normalized to TIC and/or log-transformed (log(x+1))\n",
    "\n",
    "After that, both datasets are subset to contain the same ions and cells (intersection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(adata):\n",
    "    \n",
    "    sc.pp.filter_cells(adata, min_genes=10)\n",
    "    sc.pp.filter_genes(adata, min_cells=200)\n",
    "    adata.raw = adata\n",
    "    adata.layers[\"raw_counts\"] = adata.X.copy()\n",
    "    # sc.pp.scale(adata)\n",
    "    adata.layers[\"norm_counts\"] = sc.pp.normalize_total(adata, layer='raw_counts', target_sum=None, inplace=False)['X']\n",
    "    adata.layers[\"1e4_norm_counts\"] = sc.pp.normalize_total(adata, layer='raw_counts', target_sum=1e4, inplace=False)['X']\n",
    "    \n",
    "    adata.layers[\"log_raw_counts\"] = sc.pp.log1p(adata.layers[\"raw_counts\"], copy=True)\n",
    "    adata.layers[\"log_norm_counts\"] = sc.pp.log1p(adata.layers[\"norm_counts\"], copy=True)\n",
    "    adata.layers[\"1e4_log_norm_counts\"] = sc.pp.log1p(adata.layers[\"1e4_norm_counts\"], copy=True)\n",
    "    adata.X = adata.layers[\"log_norm_counts\"]\n",
    "    \n",
    "    adata.var['median_intensity'] = np.median(adata.X, axis=0)\n",
    "    adata.var['mean_intensity'] = np.mean(adata.X, axis=0)\n",
    "    # adata_x = adata.X.copy()\n",
    "    # adata_x[adata_x == 0] = np.nan\n",
    "    # adata.var['median_intensity_nonzero'] = np.nanmedian(adata_x, axis=0)\n",
    "    \n",
    "    \n",
    "preprocess(adata)\n",
    "preprocess(adata_cor)\n",
    "\n",
    "print(adata.shape)\n",
    "print(adata_cor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 120.971995,
     "end_time": "2022-12-01T11:32:46.203388",
     "exception": false,
     "start_time": "2022-12-01T11:30:45.231393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dimred_umap(adata, layer=None, min_dist=0.5):\n",
    "    if layer is not None:\n",
    "        adata.layers['default_X'] = adata.X\n",
    "        adata.X = adata.layers[layer]\n",
    "    \n",
    "    sc.pp.pca(adata)\n",
    "    sc.pp.neighbors(adata, n_neighbors=50, metric='cosine')\n",
    "    sc.tl.umap(adata, min_dist=min_dist, spread=1.0, random_state=1, n_components=2)\n",
    "    #sc.pl.umap(adata, color=['well', condition_name], palette='cividis')\n",
    "    f = osm.pl.highlight_scatterplot(\n",
    "        data = adata,\n",
    "        obsm_key = \"X_umap\",\n",
    "        hue = condition_name,\n",
    "        col = condition_name,\n",
    "        palette = \"cividis\",\n",
    "        trim_axes=True,\n",
    "        height = 5,\n",
    "        scatter_kwargs = dict(s=5)\n",
    "    )\n",
    "\n",
    "    f.add_legend(markerscale=3)\n",
    "    \n",
    "    if layer is not None:\n",
    "        adata.X = adata.layers['default_X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermixing_layer(adata, adata_cor, condition_name, measures = ['X_pca', 'X_umap'], layer=None):\n",
    "    if layer is not None:\n",
    "        adata.layers['default_X'] = adata.X\n",
    "        adata.X = adata.layers[layer]\n",
    "        adata_cor.layers['default_X'] = adata_cor.X\n",
    "        adata_cor.X = adata_cor.layers[layer]\n",
    "    \n",
    "    summaries = intermixing({'uncorrected': adata, 'ISM correction': adata_cor}, condition_name = condition_name, measures = measures)\n",
    "    \n",
    "    if layer is not None:\n",
    "        adata.X = adata.layers['default_X']\n",
    "        adata_cor.X = adata_cor.layers['default_X']\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different options for scaling and transforming the data are shown in the following:\n",
    "\n",
    "1. raw values\n",
    "2. log transformation\n",
    "3. TIC normalization\n",
    "4. TIC normalization and log transformation\n",
    "5. normalization to a fixed count (10^4)\n",
    "6. normalization to a fixed count (10^4) and log transformation\n",
    "\n",
    "The normalization to a fixed count has a slightly different effect than TIC normalization. The former normalizes all counts per cell to the given target sum so that all cells from the uncorrected and the corrected set are scaled to this count. In contrast, the latter retains the differences between the datasets by normalizing to the median count across cells in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimred_umap(adata, layer='raw_counts')\n",
    "dimred_umap(adata_cor, layer='raw_counts')\n",
    "intermixing_layer(adata, adata_cor, condition_name, measures = ['X_pca', 'X_umap'], layer='raw_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimred_umap(adata, layer='log_raw_counts')\n",
    "dimred_umap(adata_cor, layer='log_raw_counts')\n",
    "intermixing_layer(adata, adata_cor, condition_name, measures = ['X_pca', 'X_umap'], layer='log_raw_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimred_umap(adata, layer='norm_counts')\n",
    "dimred_umap(adata_cor, layer='norm_counts')\n",
    "intermixing_layer(adata, adata_cor, condition_name, measures = ['X_pca', 'X_umap'], layer='norm_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimred_umap(adata, layer='log_norm_counts')\n",
    "dimred_umap(adata_cor, layer='log_norm_counts')\n",
    "intermixing_layer(adata, adata_cor, condition_name, measures = ['X_pca', 'X_umap'], layer='log_norm_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimred_umap(adata, layer='1e4_norm_counts')\n",
    "dimred_umap(adata_cor, layer='1e4_norm_counts')\n",
    "intermixing_layer(adata, adata_cor, condition_name, measures = ['X_pca', 'X_umap'], layer='1e4_norm_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimred_umap(adata, layer='1e4_log_norm_counts')\n",
    "dimred_umap(adata_cor, layer='1e4_log_norm_counts')\n",
    "intermixing_layer(adata, adata_cor, condition_name, measures = ['X_pca', 'X_umap'], layer='1e4_log_norm_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00762,
     "end_time": "2022-12-01T13:10:24.914497",
     "exception": false,
     "start_time": "2022-12-01T13:10:24.906877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before analysis, asserting that the two data files were deconvoluted in the same way. Specifically, the corrected dataframe cannot have non-zero values at positions where the uncorrected dataframe has zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert not any(pd.Series(np.array((adata.to_df() == 0) & (adata_cor.to_df()!= 0)).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['correction'] = 'uncorrected'\n",
    "adata_cor.obs['correction'] = 'ISM correction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects of the correction on different molecules\n",
    "\n",
    "The ISM correction is performed per ion on the logarithmized intensity / sampling proportion ratio. The underlying quantile regression can only be computed with a minimum number of datapoints. If an ion has less than 10 datapoints, the quantile regression is instead computed based on a reference pool of ions.\n",
    "In the following, the resulting slopes by which all ions have been corrected are visualized. Ions that were corrected using the reference pool are shown separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(adata_cor.var[['mean_correction_quantreg_slope', 'corrected_only_using_pool']], col='corrected_only_using_pool', hue='corrected_only_using_pool', sharey=False)\n",
    "grid.map(sns.histplot, 'mean_correction_quantreg_slope', bins=30)\n",
    "cor_pool = list(adata_cor.var[adata_cor.var['corrected_only_using_pool'] == True].index)\n",
    "adata_cor.var['corrected_only_using_pool'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the slopes of the correction but also the logfoldchanges between corrected and uncorrected cells, one can infer the extent of alteration of different metabolites in the correction. These measures not necessarily correlate, thus the degree of correction of ions has to be evaluated on individual datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.evaluation\n",
    "from importlib import reload\n",
    "reload(src.evaluation)\n",
    "from src.evaluation import MetaboliteAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_raw = MetaboliteAnalysis(adata=adata, adata_cor=adata_cor, condition_name = condition_name, \n",
    "                        obs_columns = ['list_TPO'],\n",
    "                        var_columns = ['corrected_only_using_pool', 'mean_correction_quantreg_slope', \n",
    "                                       'n_cells','median_intensity', 'mean_intensity', 'sum_correction_using_ion_pool'],\n",
    "                       use_raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_raw.pair_plot(exclude_ref_corrected = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_raw.volcano_plot(exclude_ref_corrected = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups_tracksplot(ma_raw.conc_adata, groupby='correction', dendrogram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_cor.obs['n_pixels'] = [i.count(';')+1 for i in adata_cor.obs['list_TPO']]\n",
    "strat_cell_list = list(adata_cor.obs.groupby('n_pixels', group_keys=False).apply(lambda x: x.sample(1)).index)[:6]\n",
    "strat_cell_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the metabolic profiles of sampled cell generated from 1 and increasing numbers of ablation marks. The first row has the uncorrected raw ion intensities, the second row the corrected raw ion intensities and the third row the correction ratio/quotient between the two ( $correction\\_ratio = \\frac{I_{corrected}}{I_{uncorrected}}$ ). Most ions have the same correction ratio in a given cells, some have a higher ratio (smaller slope, less ISM correction) and some have a lower ratio (steeper slope, stronger ISM correction). The distribution of ion-specific correction ratios in the same cells is shown, separately for self-corrected and pool-corrected ions, in density plots underneath the metabolic profiles. Black horizontal and vertical lines show the sampling proportion of all ablation marks that were combined to the respective cell. Especially from the density plots, it becomes obvious that the majority of ions have correction ratios that colocalize with the pixels' sampling ratios. This can be explained by the fact that most ions had a correction slope of ~-1, the pool-corrected ions had all the same slope close to -1. Thus, these ions are down-corrected by multiplying with ~1 times their sampling proportion. Since many ions seem to occur only in one of the underlying ablation marks, the distribution of correction ratios has prominent peaks and few values between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 68.431894,
     "end_time": "2022-12-01T13:12:34.300402",
     "exception": false,
     "start_time": "2022-12-01T13:11:25.868508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ma_raw.quotient_plot(show_cells=strat_cell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ma_raw.top_ion_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 38.829602,
     "end_time": "2022-11-25T11:27:33.222739",
     "exception": false,
     "start_time": "2022-11-25T11:26:54.393137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = ma_raw.save_matrix(save_to_path = analysis_path, safe_to_name = project, save_figures=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same analysis is then carried out for the TIC-corrected and log-transformed data: Here, the differences between uncorrected and ISM-corrected data are much more subtle. This corresponds better with the UMAPs further down, as they also show very little noticebly differences between uncorrected and ISM-corrected datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = MetaboliteAnalysis(adata=adata, adata_cor=adata_cor, condition_name = condition_name, \n",
    "                        obs_columns = ['list_TPO'],\n",
    "                        var_columns = ['corrected_only_using_pool', 'mean_correction_quantreg_slope', \n",
    "                                       'n_cells','median_intensity', 'mean_intensity', 'sum_correction_using_ion_pool'],\n",
    "                       use_raw = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups_tracksplot(ma.conc_adata, groupby='correction', dendrogram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.quotient_plot(show_cells=strat_cell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.top_ion_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the datasets\n",
    "\n",
    "In the following, the uncorrected and ISM-corrected datasets are compared using methods of a typical single-cell analysis. Unless specified otherwise, the data was preprocessed using TOC normalization and log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimred_pca(adata):\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pl.pca_overview(adata, color=['well', condition_name], palette='cividis')\n",
    "\n",
    "dimred_pca(adata)\n",
    "dimred_pca(adata_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimred_umap(adata)\n",
    "dimred_umap(adata_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.cluster import completeness_score\n",
    "# from sklearn.metrics import accuracy_score, silhouette_score\n",
    "# \n",
    "# def kmeans_clust(adata):\n",
    "#     n_clusters = len(adata.obs[condition_name].value_counts())\n",
    "#     kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(adata.X)\n",
    "#     adata.obs['kmeans'] = kmeans.labels_.astype(str)\n",
    "# \n",
    "#     sc.tl.leiden(adata, resolution=2)\n",
    "# \n",
    "#     leiden = np.array(adata.obs['leiden'].values)\n",
    "#     leiden_curated = np.copy(leiden)\n",
    "#     fc = np.array(adata.obs[condition_name].values)\n",
    "#     for cluster in np.unique(leiden):\n",
    "#         labels, counts = np.unique(fc[leiden == cluster], return_counts=True)\n",
    "#         leiden_curated[leiden == cluster] = str(labels[counts == np.max(counts)][0])\n",
    "#     adata.obs['leiden_curated'] = leiden_curated\n",
    "# \n",
    "#     sc.pl.umap(adata, color=['kmeans', 'leiden', 'leiden_curated', condition_name], palette='cividis')\n",
    "#     # print('Leiden acccuracy score: %1.4f' % accuracy_score(y_true = adata.obs[condition_name].replace(['HeLa', 'NIH3T3'], ['0', '1']), y_pred = adata.obs['leiden']))\n",
    "#     print('Curated leiden acccuracy score: %1.4f' % accuracy_score(y_true = adata.obs[condition_name], y_pred = adata.obs['leiden_curated']))\n",
    "#     print('KMeans completeness score: %1.4f' % completeness_score(adata.obs[condition_name], adata.obs['kmeans']))\n",
    "#     print('KMeans silhouette coefficient: %1.4f' % silhouette_score(adata.X, adata.obs['kmeans']))\n",
    "# \n",
    "# kmeans_clust(adata)\n",
    "# kmeans_clust(adata_cor)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = intermixing({'uncorrected': adata, 'ISM correction': adata_cor}, condition_name = condition_name, measures = ['X_pca', 'X_umap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = intermixing(\n",
    "    adata_dict = {'uncorrected': adata, 'ISM correction': adata_cor},\n",
    "    condition_name = condition_name,\n",
    "    sample_frac=0.1,\n",
    "    measures =['X_umap', 'X_pca'],\n",
    "    n_datapoints = 50,\n",
    "    sample_log = True,\n",
    "    neighborhood_size = None,\n",
    "    normalized = False,\n",
    "    show_table = [],\n",
    "    n_jobs = multiprocessing.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapz, simps\n",
    "\n",
    "def auc_intermixing(summary_dict):\n",
    "    for name, data in summary_dict.items():\n",
    "        print('Area under the curve for %s: %1.4f'%(name, trapz(data['mean'], data.index) / max(data.index)))\n",
    "\n",
    "\n",
    "auc_intermixing(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def analyse_svm_margin(adata, adata_cor, condition_name, layer=None):\n",
    "    print(layer)\n",
    "    if layer is not None:\n",
    "        adata.layers['default_X'] = adata.X\n",
    "        adata.X = adata.layers[layer]\n",
    "        adata_cor.layers['default_X'] = adata_cor.X\n",
    "        adata_cor.X = adata_cor.layers[layer]\n",
    "    \n",
    "    def get_svm_margin(adata, condition_name, size_factor = 1):\n",
    "        predictors = adata.X * size_factor\n",
    "        result = adata.obs[condition_name]\n",
    "        clf = LinearSVC(random_state=0, dual=False)\n",
    "        clf.fit(predictors, result)  \n",
    "        margin_df = pd.DataFrame({'condition': clf.classes_, 'margin': 1 / np.sqrt(np.sum(clf.coef_**2, axis=1))})\n",
    "\n",
    "        #print(margin_df)\n",
    "        return margin_df\n",
    "    \n",
    "    size_factor = np.sum(adata.X) / np.sum(adata_cor.X)\n",
    "\n",
    "    df = pd.merge(get_svm_margin(adata, condition_name), \n",
    "                  get_svm_margin(adata_cor, condition_name, size_factor = size_factor), \n",
    "                  on='condition', suffixes=['_uncorrected', '_ISM_corrected'])\n",
    "    sns.set(rc={\"figure.figsize\":(12, 5)})\n",
    "    sns.barplot(df.melt(id_vars='condition', var_name='correction', value_name='margin'), \n",
    "                x='condition', y='margin', hue='correction').set_title('Comparison of SVM margins for layer %s'%layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if layer is not None:\n",
    "        adata.X = adata.layers['default_X']\n",
    "        adata_cor.X = adata_cor.layers['default_X']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_svm_margin(adata, adata_cor, condition_name, layer='log_norm_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_svm_margin(adata, adata_cor, condition_name, layer='log_norm_counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "89b4449ee30f46b148fb6825d70934bcbb1ebdb6d5b2015fe3835362773c7289"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
