{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of ion suppression correction\n",
    "\n",
    "In this notebook, I explore different measures to quantify the effect of correcting SpaceM ion intensity data for partial pixel-cell overlap.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from src.correction import *\n",
    "from src import const\n",
    "from sklearn.cluster import KMeans\n",
    "from importlib import reload\n",
    "# import outer_spacem as osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == \"Darwin\":\n",
    "    target_path = '/Volumes/mklein/FDA_project/data/Mx_Co_Cultured'\n",
    "else:\n",
    "    target_path = '/home/mklein/FDA_project/data/Mx_Co_Cultured'\n",
    "\n",
    "condition_name = 'celltype'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditions data for the co-culture datasets is established using fluorescence microscopy. The following code is adapted from Martijn and just shows the classification of fluorescence values to celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(os.path.join(target_path, 'pipeline_files/batch_sm_matrix.h5ad'))\n",
    "adata_cor = sc.read(os.path.join(target_path, 'pipeline_files/corrected_batch_sm_matrix.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_metadata = pd.read_csv(os.path.join(target_path,'MORPHnMOL.csv'))\n",
    "condition_metadata.index = [const.CELL_PRE + str(i) for i in condition_metadata.ObjectNumber]\n",
    "condition_metadata['GFP'] = condition_metadata.Intensity_MeanIntensity_GFP_quantif\n",
    "condition_metadata['MCherry'] = condition_metadata.Intensity_MeanIntensity_mCherry_quantif\n",
    "condition_metadata['fluorescence_ratio'] = np.log(condition_metadata.GFP / condition_metadata.MCherry)\n",
    "\n",
    "#condition_metadata['celltype'] = 'HeLa' if condition_metadata.fluorescence_ratio < 0.8 else 'NIH3T3'\n",
    "condition_metadata['celltype'] = np.where(condition_metadata.fluorescence_ratio < 0.8, 'HeLa', 'NIH3T3')\n",
    "\n",
    "print(condition_metadata['celltype'].value_counts())\n",
    "\n",
    "plot = sns.relplot(data=condition_metadata, x='GFP', y='MCherry', hue='celltype')\n",
    "plot.set(xscale='log')\n",
    "plot.set(yscale='log')\n",
    "plot.set(title='Cell type attributation based on GFP / MCherry fluorescence ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The co-culture dataset was originally used in the original SpaceM manuscript. The corresponding metadata file `MORPHnMOL.csv` subsets the list of annotated molecules from 104 to 58. Consequently, only these molecules will be explored in the following. Analogously, only the cells present in both the uncorrected and corrected spatiomolecular matrices are kept for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_cells = adata.obs.index.intersection(condition_metadata.index)\n",
    "all_molecules = adata.var.index\n",
    "included_molecules = adata.var.index.intersection(condition_metadata.columns)\n",
    "\n",
    "adata = adata[included_cells, all_molecules]\n",
    "adata_cor = adata_cor[included_cells, all_molecules]\n",
    "\n",
    "print(adata.shape)\n",
    "print(adata_cor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, both spatiomolecular matrices are filtered and scaled to zero-mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(adata):\n",
    "    sc.pp.filter_cells(adata, min_genes=5)\n",
    "    sc.pp.filter_genes(adata, min_cells=1)\n",
    "    adata.raw = adata\n",
    "    # sc.pp.normalize_total(adata, target_sum=None)\n",
    "    # sc.pp.log1p(adata)\n",
    "    sc.pp.scale(adata)\n",
    "\n",
    "preprocess(adata)\n",
    "preprocess(adata_cor)\n",
    "\n",
    "\n",
    "print(adata.shape)\n",
    "print(adata_cor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['correction'] = 'uncorrected'\n",
    "adata_cor.obs['correction'] = 'ISM correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ion in adata.var_names:\n",
    "    if len(((adata.to_df()['C37H71O8P'] == 0) & (adata_cor.to_df()['C37H71O8P']!= 0)).value_counts()) > 1:\n",
    "        print(ion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_adata = ad.concat({'uncorrected': adata, 'ISM correction': adata_cor}, label='correction', index_unique='_', merge='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata=conc_adata, groupby='correction', use_raw=True, method='t-test_overestim_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ions_dea = sc.get.rank_genes_groups_df(conc_adata, group='ISM correction')\n",
    "# tops_dea = pd.concat({'strongly_corr': top_uncor, 'hardly_corr': top_cor})\n",
    "\n",
    "adata_cor.var['names'] = adata_cor.var.index\n",
    "impact_ions = pd.merge(all_ions_dea, adata_cor.var[['names', 'correction_using_ion_pool', 'correction_n_iterations', 'correction_n_datapoints', 'correction_quantreg_slope']], on='names', how='left')\n",
    "impact_ions = impact_ions.sort_values(by='scores')\n",
    "\n",
    "sign_impact_ions = impact_ions.loc[(impact_ions['pvals'] < 0.001) & \n",
    "                                   (impact_ions['scores'] < -2)]\n",
    "impact_ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bioinfokit import visuz\n",
    "# visuz.GeneExpression.volcano(df=impact_ions.replace(np.Inf, np.nan).dropna(), lfc='logfoldchanges', pv='pvals_adj', show=True)\n",
    "# impact_ions.replace(np.Inf, np.nan).dropna().sort_values('logfoldchanges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2\n",
    "\n",
    "top = 20\n",
    "impact_ions_fc = impact_ions.sort_values(by='logfoldchanges')\n",
    "\n",
    "venn2([set(impact_ions.head(top).index),\n",
    "       set(impact_ions_fc.head(top).index)],\n",
    "       set_labels = ['by slope', 'by DEA']\n",
    ")\n",
    "plt.title('strongly corrected')\n",
    "plt.show()\n",
    "venn2([set(impact_ions.tail(top).index),\n",
    "       set(impact_ions_fc.tail(top).index)],\n",
    "       set_labels = ['by slope', 'by DEA']\n",
    ")\n",
    "plt.title('hardly corrected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_adata_raw = conc_adata.copy()\n",
    "conc_adata_raw.X = conc_adata_raw.raw.X\n",
    "changed_ions_df = sc.get.obs_df(conc_adata_raw, keys=(['correction', 'celltype', 'ObjectNumber']+list(conc_adata.var_names)))\n",
    "plot_df = changed_ions_df.melt(id_vars=['correction', 'celltype', 'ObjectNumber'], var_name='ion').pivot(index=['ion', 'celltype', 'ObjectNumber'], columns='correction', values='value')\n",
    "plot_df.reset_index(level=[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_ions['pearson'] = [plot_df[plot_df.ion == ion].corr()['uncorrected']['ISM correction'] for ion in impact_ions['names']]\n",
    "sns.pairplot(impact_ions[['scores', 'logfoldchanges', 'correction_quantreg_slope', 'pearson']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_df['ISM correction_intersect'] = plot_df['ISM correction'] * [ 10 ** adata_cor.var.loc[ion, 'correction_quantreg_intersect'] for ion in plot_df['ion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ions_corr = list(impact_ions['names'].head())\n",
    "ions_uncorr = list(impact_ions['names'].tail())\n",
    "ions = ions_corr + ions_uncorr #+ ['C27H53O12P', 'C18H36O2', 'C41H80NO8P', 'C39H73O8P', 'C43H81O13P', 'C35H69O8P']\n",
    "# ions = list(set(ions))\n",
    "plot_df['group'] = ['strongly corr' if (ion in ions_corr) else 'hardly corr' if (ion in ions_uncorr) else 'other' for ion in plot_df['ion'] ]\n",
    "\n",
    "slopes = [adata_cor.var.loc[ion, 'correction_quantreg_slope'] for ion in ions]\n",
    "intersects = [adata_cor.var.loc[ion, 'correction_quantreg_intersect'] for ion in ions]\n",
    "pearson = [plot_df[plot_df.ion == ion].corr()['uncorrected']['ISM correction'] for ion in ions]\n",
    "grid = sns.FacetGrid(plot_df, col='ion', hue='group', col_wrap=5, sharex=False, sharey=False, col_order=ions, palette='cividis')\n",
    "grid.map(sns.scatterplot, 'uncorrected', 'ISM correction').add_legend()\n",
    "grid.set(aspect = 1)\n",
    "for i, ax in enumerate(grid.axes.flat): \n",
    "    lim = max([ax.get_xlim()[1], ax.get_ylim()[1]])\n",
    "    ax.set_xlim(0, lim)\n",
    "    ax.set_ylim(0, lim)\n",
    "    ax.axline((0,0), slope=1)\n",
    "    ax.text(0.04*lim, 0.8*lim, 'quantreg slope = %1.3f\\nintersect = %1.3f\\npearson r = %1.5f'%(slopes[i], intersects[i], pearson[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_ad = conc_adata_raw.copy().transpose()\n",
    "\n",
    "df = ea_ad.to_df()\n",
    "df.to_csv(os.path.join(target_path, 'Mx_coculture_lion_table.csv'))\n",
    "#sign_impact_ions['names']\n",
    "metadata = pd.concat({'sample':pd.Series(df.columns), 'condition': pd.Series(cond)}, axis = 1)\n",
    "metadata = metadata.set_index('sample')\n",
    "metadata.to_csv(os.path.join(target_path, 'Mx_coculture_metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = list(ea_ad.var['correction'])\n",
    "annot = list(ea_ad.obs_names)\n",
    "\n",
    "data = [df, annot, cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "bmet = importr('bmetenrichr', lib_loc='/home/mklein/.conda/envs/ion_suppression/lib/R/library')\n",
    "pbl = importr('pbapply', lib_loc='/home/mklein/.conda/envs/ion_suppression/lib/R/library')\n",
    "base = importr('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    scmatrix = ro.conversion.py2rpy(df)\n",
    "    annotations = ro.conversion.py2rpy(annot)\n",
    "    conditions = ro.conversion.py2rpy(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr = bmet.initEnrichment(scmatrix = base.as_matrix(scmatrix),\n",
    "                 annotations = base.as_character(annotations),\n",
    "                 conditions = base.as_character(conditions),\n",
    "                 condition_x = \"uncorrected\",\n",
    "                 condition_y = \"ISM correction\"\n",
    "                )\n",
    "\n",
    "enr = bmet.rankScore(enr, 't.test')\n",
    "enr = bmet.calcEnrichment(enr, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmet.plotEnrichment(enr, min_annotations = 1, q_value_cutoff = .2, by_statistic = \"ES\")\n",
    "bmet.plotEnrichment(enr, 1, 0.5, \"ES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library(bmetenrichr)\n",
    "\n",
    "matrix <- data[[1]]\n",
    "print(matrix[1:10,1:10])\n",
    "\n",
    "test <-\n",
    "  initEnrichment(scmatrix = data[[1]],\n",
    "                 annotations = as.character(data[[2]]),\n",
    "                 conditions = as.character(data[[3]]),\n",
    "                 condition.x = \"uncorrected\",\n",
    "                 condition.y = \"ISM correction\"\n",
    "                )\n",
    "    \n",
    "# test <- rankScore(test, ranking.by = 't.test')\n",
    "# test <- calcEnrichment(test, n = 100)\n",
    "# plotEnrichment(test, min.annotations = 1, q.value.cutoff = .2, by.statistic = \"ES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following graphs, the uncorrected data is shown before the corrected data. Initially, the data is visualized using PCA and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimred_pca(adata):\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pl.pca_overview(adata, color='celltype')\n",
    "\n",
    "dimred_pca(adata)\n",
    "dimred_pca(adata_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimred_umap(adata, min_dist = 0.5):\n",
    "    sc.pp.neighbors(adata, n_neighbors=200, metric='cosine')\n",
    "    sc.tl.umap(adata, min_dist=min_dist, spread=2.0, random_state=1, n_components=2)\n",
    "    sc.pl.umap(adata, color=condition_name)\n",
    "    # f = osm.pl.highlight_scatterplot(\n",
    "    #     data = adata,\n",
    "    #     obsm_key = \"X_umap\",\n",
    "    #     hue = condition_name,\n",
    "    #     col = condition_name,\n",
    "    #     palette = \"cividis\",\n",
    "    #     height = 5,\n",
    "    #     scatter_kwargs = dict(s=10)\n",
    "    # )\n",
    "\n",
    "    # f.add_legend(markerscale=3)\n",
    "\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "    # plt.show()\n",
    "\n",
    "dimred_umap(adata)\n",
    "dimred_umap(adata_cor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist several methods for unsupervised clustering, that can be applied to dimensionality-reduced data. Here, I show kMeans clustering, Leiden clustering and a variant of the latter (adapted from the SpaceM manuscript: curated leiden). Both kMeans and Leiden clustering appear to fail at distinguishing the two celltypes as they split the data along the short axis of the UMAP visualization. However, the celltypes are separated along the long axis. The curated Leiden algorithm from Rappez et al. finds smaller Leiden clusters and assigns them to either celltype depending on the nature of the majority of cells. This method of finer granularity does better reproduce the separation between the two celltypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import completeness_score\n",
    "from sklearn.metrics import accuracy_score, silhouette_score\n",
    "\n",
    "def clustering_methods(adata):\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(adata.X)\n",
    "    adata.obs['kmeans'] = kmeans.labels_.astype(str)\n",
    "\n",
    "    sc.tl.leiden(adata, resolution=0.3)\n",
    "    sc.tl.leiden(adata, resolution=2, key_added='leiden_fine')\n",
    "\n",
    "    leiden = np.array(adata.obs['leiden_fine'].values)\n",
    "    leiden_curated = np.copy(leiden)\n",
    "    fc = np.array(adata.obs['celltype'].values)\n",
    "    for cluster in np.unique(leiden):\n",
    "        labels, counts = np.unique(fc[leiden == cluster], return_counts=True)\n",
    "        leiden_curated[leiden == cluster] = str(labels[counts == np.max(counts)][0])\n",
    "    adata.obs['leiden_curated'] = leiden_curated\n",
    "\n",
    "    sc.pl.umap(adata, color=['kmeans', 'leiden', 'leiden_curated', 'celltype'])\n",
    "    print('Leiden acccuracy score: %1.4f' % accuracy_score(y_true = adata.obs['celltype'].replace(['HeLa', 'NIH3T3'], ['0', '1']), y_pred = adata.obs['leiden']))\n",
    "    print('Curated leiden acccuracy score: %1.4f' % accuracy_score(y_true = adata.obs['celltype'], y_pred = adata.obs['leiden_curated']))\n",
    "    print('KMeans completeness score: %1.4f' % completeness_score(adata.obs['celltype'], adata.obs['kmeans']))\n",
    "    print('KMeans silhouette coefficient: %1.4f' % silhouette_score(adata.X, adata.obs['kmeans']))\n",
    "\n",
    "clustering_methods(adata)\n",
    "clustering_methods(adata_cor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear discriminant analysis is a linear classifier that can be trained and applied to the ion intensity data in order to further examine the separation of the different conditions (celltypes). In general, the performance of the classifier depends on the underlying data, the trained model and how they work with each other. Assuming the model itself has equal performance in both cases, higher the accuracy of the classifier can be attributed to a better separation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "def test_classifier(adata, model, predictors, result, name):\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\n",
    "    scores = cross_val_score(model, predictors, result, scoring='accuracy', cv=cv, n_jobs=multiprocessing.cpu_count())\n",
    "    \n",
    "    adata.obs[name] = model.predict(adata.X)\n",
    "    sc.pl.umap(adata, color=['celltype', 'lda'])\n",
    "    print(\"Classification accuracy after 10-fold cross-validation: %1.4f (Â±%1.4f)\" % (np.mean(scores), np.std(scores)))  \n",
    "\n",
    "def LDA(adata):\n",
    "    predictors = adata.X\n",
    "    result = adata.obs['celltype']\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model.fit(predictors, result)  \n",
    "\n",
    "    test_classifier(adata, model, predictors, result, name = 'lda')\n",
    "\n",
    "LDA(adata) \n",
    "LDA(adata_cor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest(adata, max_depth = 10):\n",
    "    predictors = adata.X\n",
    "    result = adata.obs['celltype']\n",
    "    model = RandomForestClassifier(random_state=1, max_depth=max_depth)\n",
    "    model.fit(predictors, result)  \n",
    "\n",
    "    test_classifier(adata, model, predictors, result, name = 'random_forest') \n",
    "\n",
    "\n",
    "random_forest(adata) \n",
    "random_forest(adata_cor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def knn_classifier(adata, n_neighbors = 20):\n",
    "    predictors = adata.X\n",
    "    result = adata.obs['celltype']\n",
    "    nca = NeighborhoodComponentsAnalysis(random_state=1)\n",
    "    knn = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "    model = Pipeline([('nca', nca), ('knn', knn)])\n",
    "    knn.fit(predictors, result)  \n",
    "\n",
    "    test_classifier(adata, knn, predictors, result, name = 'knn')\n",
    "\n",
    "\n",
    "knn_classifier(adata) \n",
    "knn_classifier(adata_cor) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Martijn developed an intermixing metric for the separation of different conditions based on the local neighborhood (euclidian distance) of every data point in dimensionality-reduced space. I have extended this single-valued measure to a curve on neighborhood-scale and introduced a correction factor for unbalanced datasets. For the co-culture dataset, this metric shows a clear difference in the group intermixing of uncorrected and corrected ion intensities. Intermixing is almost 50% lower after correction across neighborhood sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import intermixing, intermixing_metric_sampled\n",
    "intermixing({'uncorrected': adata, 'ISM correction': adata_cor}, condition_name=condition_name, sample_frac=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better comparison to Martijns results, I also calculate the intermixing metric for the fixed neighborhood of $n=10$, with and without normalization to group imbalance. Martijn reports intermixing values of $0.152$ for ISM correction and $0.215$ for uncorrected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([intermixing_metric_sampled(adata, condition_name, neighborhood_size=[10], n_datapoints=1, label='none', normalized=True),\n",
    "intermixing_metric_sampled(adata_cor, condition_name, neighborhood_size=[10], n_datapoints=1, label='ISM', normalized=True),\n",
    "intermixing_metric_sampled(adata, condition_name, neighborhood_size=[10], n_datapoints=1, label='none', normalized=False),\n",
    "intermixing_metric_sampled(adata_cor, condition_name, neighborhood_size=[10], n_datapoints=1, label='ISM', normalized=False)], axis=0, keys=['none', 'ISM', 'none_raw', 'ISM_raw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As visible in UMAP space, the two celltypes are separated along the long axis of the cluster instead of the short axis. This may indicate that the metabolic profiles within two populations themselves are more heterogenic than between them. Thus an additional biological or technical factor seems to influence the metabolic profiles. To investigate this furter, I did a differential expression analysis between the two leiden clusters. On top of that, it would be useful to complement this with an enrichment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata=adata, groupby='leiden', use_raw=True, method='t-test_overestim_var', n_genes=25)\n",
    "# sc.pl.rank_genes_groups_tracksplot(adata, groupby='leiden')\n",
    "sc.pl.rank_genes_groups_violin(adata, groups=['0', '1'])\n",
    "sc.get.rank_genes_groups_df(adata, group='0')['names'].to_csv('data/Mx_Co_Cultured/metabolite-set.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "89b4449ee30f46b148fb6825d70934bcbb1ebdb6d5b2015fe3835362773c7289"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
